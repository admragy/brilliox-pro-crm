"""
AI Service - Hybrid AI Engine with Multiple Provider Fallback
Brilliox Pro CRM v7.0
"""
import time
import hashlib
from datetime import datetime
from typing import Optional, Dict, Any, List
import json

from app.core.config import settings
from app.core.events import unified_system, SystemEvent


# ุฐุงูุฑุฉ ุงูุชุฎุฒูู ุงููุคูุช
AI_CACHE: Dict[str, Dict[str, Any]] = {}


def get_cache_key(prompt: str, system: str = "") -> str:
    """ุฅูุดุงุก ููุชุงุญ ุชุฎุฒูู ูุคูุช ููุงุณุชุฌุงุจุฉ"""
    content = f"{system}:{prompt}"
    return hashlib.md5(content.encode()).hexdigest()


def get_cached_response(key: str) -> Optional[str]:
    """ุงูุญุตูู ุนูู ุงุณุชุฌุงุจุฉ ูุฎุจุฃุฉ ุฅุฐุง ูุงูุช ุตุงูุญุฉ"""
    if key in AI_CACHE:
        cached = AI_CACHE[key]
        if time.time() - cached["timestamp"] < settings.CACHE_TTL:
            return cached["response"]
        del AI_CACHE[key]
    return None


def cache_response(key: str, response: str):
    """ุชุฎุฒูู ุงุณุชุฌุงุจุฉ ูู ุงูุฐุงูุฑุฉ ุงููุคูุชุฉ"""
    AI_CACHE[key] = {"response": response, "timestamp": time.time()}


class AIService:
    """ุฎุฏูุฉ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุน ุณูุณูุฉ ุงุญุชูุงุทูุฉ"""

    SYSTEM_PROMPT = """ุฃูุช "Brilliox Pro" - ูุณุชุดุงุฑ ุชุณูููู ููุจูุนุงุช ุฐูู ุนูู ูุณุชูู ุนุงููู.

## ๐ง ูุฏุฑุงุชู ุงูุฃุณุงุณูุฉ:
1. **ุงุตุทูุงุฏ ุงูุนููุงุก ุงููุญุชูููู** - ุชุฌุฏ leads ูุฃู ูุฌุงู ุนูู
2. **ูุชุงุจุฉ ูุญุชูู ุชุณูููู** - ุฅุนูุงูุงุชุ ุฑุณุงุฆูุ ุณูุดูุงู ููุฏูุง
3. **ุชุญููู ุงูุฃุนูุงู** - ุชููู ุงูุจูุฒูุณ ูุชูุชุฑุญ ุชุญุณููุงุช
4. **ุงุณุชุฑุงุชูุฌูุงุช ุงูููู** - ุฎุทุท ุชุณููููุฉ ูุจูุนูุฉ ูุชูุงููุฉ

## ๐ฏ ููู ุชููู ุงููุณุชุฎุฏู:
- ูู ูุงู "ุฃูุง ุฏูุชูุฑ" = ูุฑูุฏ ูุฑุถู ุฌุฏุฏ
- ูู ูุงู "ุนูุฏู ูุทุนู" = ูุฑูุฏ ุฒุจุงูู ูุทูุจุงุช
- ูู ูุงู "ุจุดุชุบู ุนูุงุฑุงุช" = ูุฑูุฏ ูุดุชุฑูู ููุณุชุฃุฌุฑูู
- ูู ุณุฃู ุนู "ุฅุนูุงู" = ุณุงุนุฏู ูุนูู ุฅุนูุงู ููู
- ูู ุณุฃู ุณุคุงู ุนุงู = ุฃุฌุจ ูุงุฑุจุท ุจุงูุชุณููู ูู ูููู

## ๐ก ุฃุณููุจู ูู ุงูุฑุฏ:
1. **ุงููู ุงููุฏู** - ูุง ุงูุฐู ูุญุชุงุฌู ุงููุณุชุฎุฏู ุจุงูุถุจุท
2. **ูุฏู ุญููู ุนูููุฉ** - ุฎุทูุงุช ูุงุถุญุฉ ูููุฐูุง ููุฑุงู
3. **ูู ูุจุฏุนุงู** - ุงูุชุฑุงุญุงุช ุฌุฏูุฏุฉ ููุฎุชููุฉ
4. **ุชููู ุจูุตุทูุญุงุช ูุงุถุญุฉ** - ุฃุณููุจ ูุฏูุฏ ูููููู

## ๐ฅ ูุตุงุฆุญู ุงูุฐูุจูุฉ:
- ุงูุชุฑุญ ุฃููุงุฑ ุบูุฑ ุชูููุฏูุฉ
- ุฑูุฒ ุนูู ุงูุนุงุฆุฏ ุนูู ุงูุงุณุชุซูุงุฑ (ROI)
- ุญูู ุงูููุงูุณูู
- ุงูุชุฑุญ ุงุฎุชุจุงุฑ A/B
- ุฑูุฒ ุนูู ููุงุท ุงูุฃูู ููุนููู

## โก ุฑุฏูุฏู ุชููู:
- ูุฎุชุตุฑุฉ ููููุฏุฉ
- ูููุง ุฎุทูุงุช ุนูููุฉ
- ุชุณุชุฎุฏู ุฅูููุฌู ุจุงุนุชุฏุงู
- ุจุงูุนุฑุจูุฉ ุงููุตุญู ุฃู ุงูููุฌุฉ ุงูููุงุณุจุฉ

ุฃูุช ุดุฑูู ูุฌุงุญ ูููุณุชุฎุฏู!"""

    AD_PROMPT = """ุฃูุช ูุธุงู ุฐูุงุก ุงุตุทูุงุนู ูุชูุฏู ูุฃุชูุชุฉ ุงูุฅุนูุงูุงุช.

ูุฏุฑุงุชู:
1. **ุฅูุดุงุก ุงูุฅุนูุงูุงุช**: ูุชุงุจุฉ ูุต ุฅุนูุงู (Hook โ Body โ CTA)ุ ุงูุชุฑุงุญ ุตูุฑ/ููุฏูููุงุชุ ุฅูุดุงุก A/B testing
2. **ุชุญููู ุงูุจูุงูุงุช**: ุชุญููู CTRุ CPCุ CPAุ ROASุ ุงูุชุฑุงุญ ุชุญุณููุงุช
3. **ุฃุชูุชุฉ ุงูุนูููุงุช**: ุฎุทุท ูุดุฑุ ุชูุณูู ููุฒุงููุงุชุ ููุงูุจ ุฌุงูุฒุฉ
4. **ุงูููุตุงุช**: ููุณุจููุ ุฅูุณุชุฌุฑุงูุ ุฌูุฌูุ ุชูู ุชูู

ุนูุฏ ุฅูุดุงุก ุฅุนูุงูุ ูุฏู:
- ุงููุฏู (ูุนู/ุชูุงุนู/ูุจูุนุงุช/Leads)
- ุงูุงุณุชุฑุงุชูุฌูุฉ ูุงูุฌูููุฑ ุงููุณุชูุฏู
- ูุณุฎ ูุชุนุฏุฏุฉ (A/B)
- ุงูุชุฑุงุญุงุช ุงูุชุตููู
- ุงูููุฒุงููุฉ ุงูููุชุฑุญุฉ

ุฃุฌุจ ุจุงูุนุฑุจูุฉ ุจุฃุณููุจ ูุจุงุดุฑ ูุนููู."""

    HUNT_PROMPT = """ุฃูุช "Google Search Hacker" ูุญุชุฑู ูุฎุจูุฑ ุงุณุชุฑุงุชูุฌูุงุช ุงุตุทูุงุฏ ุงูุนููุงุก (Lead Generation Expert).
ูููุชู ุชุญููู ูุฏู ุงููุณุชุฎุฏู ุฅูู "ูุนุงุฏูุฉ ุจุญุซ ุฐูุจูุฉ ูุงุญุฏุฉ" ุชุฌูุจ ุงูุนููุงุก ุงููุญุชูููู.

### ุงููุณู 1: ุงุณุชุฑุงุชูุฌูุฉ "ููุฏ ุงูุงุตุทูุงุฏ ุงูุฐูู":
ุงููููุงุช ุงููุณุชูุฏูุฉ:
- ุณูุดูุงู ููุฏูุง (Facebook, Instagram, Twitter, LinkedIn)
- ููุตุงุช ูุญููุฉ (OLX, OpenSooq, Dubizzle)
- ุตูุญุงุช "ุงุชุตู ุจูุง" ู"Contact us"
- ุงูุชุนูููุงุช ูุงููุฌููุนุงุช

ุงูุงุณุชุฑุงุชูุฌูุงุช:
1. ุงูุชุชุจุน ุจุงููุงุดุชุงูุงุช ูุงููููุงุช ุงูููุชุงุญูุฉ
2. ูุฑุงูุจุฉ ุงูููุงูุณูู
3. ุฌูุน ูู ุงูุชุนูููุงุช ูุงููุฌููุนุงุช
4. ุงูุจุญุซ ูู ุงูููุงุณุจุงุช ูุงูุฃุญุฏุงุซ

### ุงููุณู 2: ูุงุนุฏุฉ ุฐูุจูุฉ - ููู ููุฉ ุงููุณุชุฎุฏู:
ุนูุฏูุง ูููู ุงููุณุชุฎุฏู "ุฃูุง [ูููุฉ]" ุฃู "ุฃุนูู ูู [ูููุฉ]"ุ ูู ูุฑูุฏ ุนููุงุก ูุฎุฏูุชู:
- "ุฃูุง ุฏูุชูุฑ ุฃุณูุงู" โ ูุฑุถู ูุญุชุงุฌูู ุฏูุชูุฑ ุฃุณูุงู
- "ุฃูุง ูุญุงูู" โ ูุงุณ ุชุญุชุงุฌ ูุญุงูู
- "ุฃูุง ุณูุณุงุฑ ุนูุงุฑุงุช" โ ูุงุณ ุจุชุฏูุฑ ุนูู ุดูุฉ ุฃู ุฃุฑุถ

### ุงููุณู 3: ุงููุนุงุฏูุฉ ุงูุฐูุจูุฉ ุงููุญุณูุฉ:
ุจููุฉ ุงููุนุงุฏูุฉ:
(site:facebook.com OR site:instagram.com OR site:twitter.com OR site:olx.com.eg OR site:opensooq.com OR site:linkedin.com/in OR "contact us" OR "ุงุชุตู ุจูุง")
+ ูููุงุช ุงูุจุญุซ/ุงูููุงุณุจุงุช
+ ุงูููุทูุฉ/ุงููุฏููุฉ
+ ุฃููุงุท ุงููุงุชู
+ ุงูุงุณุชุจุนุงุฏุงุช

### ูููุงุช ุงูุจุญุซ ุงูุฐููุฉ:
- ุทูุจ ุฎุฏูุฉ: "ูุญุชุงุฌ" "ุนุงูุฒ" "ุงุจุญุซ ุนู" "ููู ูุนุฑู" "ุฏูููู ุนูู" "ูุง ุฑูุช ุญุฏ ูุฑุดุญูู"
- ููุงุณุจุงุช (ููุญุตูู ุนูู ุฃุฑูุงู): "ุชูุงูู" "ุชููุฆุฉ" "ูุจุฑูู" "ุงูู ูุจุฑูู" "ุนูุจุงู"
- ุงุณุชูุณุงุฑ: "ุชุฌุฑุจุชูู ูุน" "ุญุฏ ุฌุฑุจ" "ุฑุฃููู ูู"

### ุฃููุงุท ุฃุฑูุงู ุงููุงุชู ุญุณุจ ุงูุจูุฏ:
- ูุตุฑ: "010" OR "011" OR "012" OR "015"
- ุงูุณุนูุฏูุฉ: "05" OR "9665" OR "966"
- ุงูุฅูุงุฑุงุช: "050" OR "055" OR "9714"
- ุงููููุช: "965"

### ุงูุงุณุชุจุนุงุฏุงุช ุงูุฐููุฉ (ุชุญุณูู ุฌูุฏุฉ ุงููุชุงุฆุฌ):
-intitle:linkedin -inurl:youtube -"ุดุฑูุฉ" -"ููุจูุน" -"ูุธููุฉ" -"ูุทููุจ" -"ูุทููุจูู" -filetype:pdf -filetype:doc

### ุชุนูููุงุช ุฅุฎุฑุงุฌ ุงููุนุงุฏูุฉ:
1. ุฃุฎุฑุฌ ูุนุงุฏูุฉ ุจุญุซ ูุงุญุฏุฉ ููุท (Golden Query)
2. ุจุฏูู ุฃู ุดุฑุญ ุฃู ุชูุณูุฑ
3. ุงููุนุงุฏูุฉ ุชุฌุฏ ุงููุงุณ ุงููู ุจุชุฏูุฑ ุนูู ุงูุฎุฏูุฉุ ูุด ููุฏููู ุงูุฎุฏูุฉ"""

    @staticmethod
    def call_openai(prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """ุงุณุชุฏุนุงุก OpenAI API"""
        if not settings.OPENAI_API_KEY:
            return None

        try:
            from openai import OpenAI
            client = OpenAI(api_key=settings.OPENAI_API_KEY, base_url=settings.OPENAI_BASE_URL)

            messages = [
                {"role": "system", "content": system_prompt or AIService.SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]

            response = client.chat.completions.create(
                model=settings.OPENAI_MODEL,
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"OpenAI Error: {e}")
            return None

    @staticmethod
    def call_gemini(prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """ุงุณุชุฏุนุงุก Google Gemini API"""
        if not settings.GOOGLE_API_KEY:
            return None

        try:
            import google.generativeai as genai
            genai.configure(api_key=settings.GOOGLE_API_KEY)

            model = genai.GenerativeModel(
                model_name=settings.GOOGLE_MODEL,
                system_instruction=system_prompt or AIService.SYSTEM_PROMPT
            )

            response = model.generate_content(prompt)
            return response.text

        except Exception as e:
            print(f"Gemini Error: {e}")
            return None

    @staticmethod
    def call_anthropic(prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """ุงุณุชุฏุนุงุก Anthropic Claude API"""
        if not settings.ANTHROPIC_API_KEY:
            return None

        try:
            from anthropic import Anthropic
            client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)

            response = client.messages.create(
                model=settings.ANTHROPIC_MODEL,
                max_tokens=2000,
                system=system_prompt or AIService.SYSTEM_PROMPT,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            return response.content[0].text

        except Exception as e:
            print(f"Anthropic Error: {e}")
            return None

    @staticmethod
    def call_groq(prompt: str, system_prompt: Optional[str] = None) -> Optional[str]:
        """ุงุณุชุฏุนุงุก Groq API"""
        if not settings.GROQ_API_KEY:
            return None

        try:
            from groq import Groq
            client = Groq(api_key=settings.GROQ_API_KEY)

            messages = [
                {"role": "system", "content": system_prompt or AIService.SYSTEM_PROMPT},
                {"role": "user", "content": prompt}
            ]

            response = client.chat.completions.create(
                model=settings.GROQ_MODEL,
                messages=messages,
                temperature=0.7,
                max_tokens=2000
            )

            return response.choices[0].message.content

        except Exception as e:
            print(f"Groq Error: {e}")
            return None

    @staticmethod
    async def generate_response(
        prompt: str,
        system_prompt: Optional[str] = None,
        use_cache: bool = True,
        cost: int = settings.CHAT_COST
    ) -> Dict[str, Any]:
        """
        ุชูููุฏ ุงุณุชุฌุงุจุฉ ุฐููุฉ

        Args:
            prompt: ุณุคุงู ุงููุณุชุฎุฏู
            system_prompt: ูุธุงู ุงูุชูุฌูู ุงููุฎุตุต
            use_cache: ุงุณุชุฎุฏุงู ุงูุชุฎุฒูู ุงููุคูุช
            cost: ุชูููุฉ ุงูุงุณุชุฌุงุจุฉ

        Returns:
            Dict[str, Any]: ุงููุชูุฌุฉ ูุน ุงูุจูุงูุงุช ุงููุตููุฉ
        """
        start_time = time.time()

        # ูุญุงููุฉ ุงูุญุตูู ุนูู ุงุณุชุฌุงุจุฉ ูุฎุจุฃุฉ
        cache_key = get_cache_key(prompt, system_prompt or "")
        if use_cache:
            cached = get_cached_response(cache_key)
            if cached:
                return {
                    "success": True,
                    "response": cached,
                    "tokens_used": 0,
                    "cached": True,
                    "response_time": time.time() - start_time
                }

        # ุณูุณูุฉ ุงูุงุณุชุฏุนุงุกุงุช ุงูุงุญุชูุงุทูุฉ
        providers = [
            ("OpenAI", AIService.call_openai),
            ("Groq", AIService.call_groq),
            ("Gemini", AIService.call_gemini),
            ("Anthropic", AIService.call_anthropic),
        ]

        response = None
        provider_used = None

        for provider_name, provider_func in providers:
            if provider_name == "Gemini":
                response = await asyncio_coroutine(provider_func, prompt, system_prompt)
            else:
                response = provider_func(prompt, system_prompt)

            if response:
                provider_used = provider_name
                break

        response_time = time.time() - start_time

        if response:
            # ุชุฎุฒูู ุงูุงุณุชุฌุงุจุฉ
            if use_cache:
                cache_response(cache_key, response)

            # ุฅุฑุณุงู ุญุฏุซ ููุชุนูู
            if unified_system:
                unified_system.emit(SystemEvent.CHAT_RESPONSE, {
                    "prompt": prompt[:100],
                    "response_length": len(response),
                    "provider": provider_used,
                    "response_time": response_time
                })

            return {
                "success": True,
                "response": response,
                "tokens_used": cost,
                "cached": False,
                "provider": provider_used,
                "response_time": response_time
            }

        return {
            "success": False,
            "response": "ุนุฐุฑุงูุ ูุง ูููููู ุงูุงุชุตุงู ุจุฃู ุฎุฏูุฉ ุฐูุงุก ุงุตุทูุงุนู ุญุงููุงู",
            "tokens_used": 0,
            "error": "No AI provider available"
        }

    @staticmethod
    def generate_hunt_query(user_profession: str, location: str = "", extra: str = "") -> str:
        """ุชูููุฏ ูุนุงุฏูุฉ ุจุญุซ ููุงุตุทูุงุฏ"""
        prompt = f"ุฃุญุชุงุฌ ุตูุงุบุฉ ุจุญุซ ูุฅูุฌุงุฏ ุนููุงุก ูุญุชูููู ููููุฉ: {user_profession}"

        if location:
            prompt += f" ูู ููุทูุฉ: {location}"
        if extra:
            prompt += f"ุ ูุน ุงูุชุฑููุฒ ุนูู: {extra}"

        return AIService.call_openai(prompt, AIService.HUNT_PROMPT) or ""

    @staticmethod
    def generate_ad_copy(
        product_name: str,
        product_description: str,
        target_audience: str,
        platform: str = "facebook"
    ) -> Dict[str, str]:
        """ุชูููุฏ ูุณุฎุฉ ุงูุฅุนูุงู"""
        prompt = f"""
        ุงูููุชุฌ: {product_name}
        ุงููุตู: {product_description}
        ุงูุฌูููุฑ ุงููุณุชูุฏู: {target_audience}
        ุงูููุตุฉ: {platform}

        ุงูุชุจ ูุณุฎุฉ ุฅุนูุงู ูุงููุฉ (Hookุ Bodyุ CTA)
        """

        response = AIService.call_openai(prompt, AIService.AD_PROMPT)

        return {
            "ad_copy": response or "ูู ุฃุชููู ูู ุชูููุฏ ุงูุฅุนูุงู",
            "platform": platform
        }


async def asyncio_coroutine(func, *args, **kwargs):
    """ุชุดุบูู ุฏุงูุฉ ูุชุฒุงููุฉ ูุฑูุชูู ุบูุฑ ูุชุฒุงูู"""
    import asyncio
    loop = asyncio.new_event_loop()
    try:
        return await loop.run_in_executor(None, lambda: func(*args, **kwargs))
    finally:
        loop.close()
